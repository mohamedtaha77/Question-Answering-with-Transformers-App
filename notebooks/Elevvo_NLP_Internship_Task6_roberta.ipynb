{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1cnuVtZi3BN"
   },
   "source": [
    "<h1><center></center></h1>\n",
    "<h1><center>Elevvo Internship</center></h1>\n",
    "<h1><center>Task 6</center></h1>\n",
    "<h2><center>Question Answering with Transformers</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTUrtI7Ui_CB"
   },
   "source": [
    "# **Hands on Task 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wtoPzy3jE8j"
   },
   "source": [
    "This notebook uses RoBERTa Base for QA, known for its robustness across NLP tasks.\n",
    "We test its performance against BERT and DistilBERT.\n",
    "\n",
    "**⚙️ Steps**\n",
    "\n",
    "- Preprocess dataset (context + question + answer).\n",
    "\n",
    "- Tokenize with RobertaTokenizer.\n",
    "\n",
    "- Fine-tune RobertaForQuestionAnswering.\n",
    "\n",
    "- Evaluate EM and F1, benchmarked against BERT & DistilBERT.\n",
    "\n",
    "- Save model in folder: qa_model_roberta-base/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PufvTm1TjNt-"
   },
   "source": [
    "# **1- Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkD_vYFejTlx"
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fbv-hZ6HjdFZ",
    "outputId": "793135ab-743c-42e9-9244-3e00444701e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate evaluate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcIrwHmhjkAQ"
   },
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HP2nWhTAjsTS"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ur2thLr-jyI_"
   },
   "source": [
    "**Set random seeds and device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UeiZwdFmj5L0",
    "outputId": "c6dd86c0-d1ba-4712-fd51-482e3a643e5d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N8HHbO-kI0f"
   },
   "source": [
    "**Load the SQuAD v1.1 dataset from Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "b206eeab8ad04f6d9d95cb44d0491622",
      "d4be8d11e011428c8b017feacaac8e83",
      "1404177aae1446b394b22e2f70ab6a19",
      "4163066551454171a1461d6e2ba8c67f",
      "74156f56c6bc4f56b42bce2b111d90bf",
      "e25bc529fc584bca9d57ac81f22762d4",
      "09d78ef85b984c0084312ed6ea4e1e55",
      "78ad90a6ef0e4b3abdfd4a417c7d731a",
      "47823b99f4d54996adb7b77b110f4477",
      "e4d55109e1ba4b88ac827b033c7b1a55",
      "aabaace74f8b4ee5ad6626e3cea149a6",
      "7e28c83b49e34b91a75a65f5c5e41d4c",
      "f2221844d64146f7a4bf5ef5cdc77614",
      "dbf34ff0bf824d9abff86892c27d158a",
      "1a7d081485c140a0a8e0cfe99ac62e32",
      "8e4c7bf5780e4c4792e0f6137c399226",
      "0081f1a04b6f487385a1c91b3f6af178",
      "6ff32f7238a14f9eaf5a6a5fa9fe0274",
      "f745075a5dac46a0be0c36c739d88c1c",
      "c07937b6692440e085bb8241dbf7a61b",
      "9d36227d0fd041e1a4e7a29f7caa9d19",
      "dd91ad51ce4f49ec85d14209e64361d3",
      "2e449ed4ff2d41c7bf8f9a44748c8b64",
      "7b21d0902b43487a83f4b838c72f89bb",
      "32c7522392814fbc9d54b3e119003992",
      "abddb540d7934ca2896d675090a61ff0",
      "ddef6ba3654a4e86a24d49951e514af6",
      "719465ea81034a0dbddf56cbf41a0002",
      "2c66ac41b83647d5b163c8e515befdcf",
      "e8a04e2d1e4d4c51aa039ceb1532f2c3",
      "dc2ddc4e529b4e69bda6e63790a868ff",
      "2bf3338337db4065a1b412c76c6468c0",
      "1b91763bb4774672b388c2dd04eec308",
      "2f6d687a0ce143c98f2d1585e125035e",
      "a622add25d75433a9269ccb1b3988525",
      "44ee422b651046c5abf04c8a151dbdc9",
      "20129a54467f4e4fa4f854c681ea0ebd",
      "0ed8e4edff4a4cbfad6273b81a8ee20f",
      "4aacf54c05404518b8e629a63baccbab",
      "148d5feab25d49ffa6e74a9f146a282a",
      "8aa07f0fd2dc4b12a97037d55329be4b",
      "e0c80d4df31145f89973c85eaacd29e2",
      "85802d7486b84b5da772941e0c6030db",
      "c7d97198d33e42b9bd50bddabc53e4e2",
      "d325f23f1dee4b238626402c68c470f3",
      "bb4491cf0ea24f248e58953fd1348fed",
      "ccdc5ec55c394a78a60027bea8f6d5c9",
      "8cd1239e134f4ba9b5951ee3bb0c6ffc",
      "a27aa40b7e104534b5f267b0b67f5c0a",
      "bf09b155127e41cab4a3b097230e743b",
      "ab9d5ca65c224f30868dff49dbe751f2",
      "c404b46679fd448f88a4858619508604",
      "7bd5267d7a114ffaa4cf9b9af50df3de",
      "2a4c1be2ba7447f99ec365295d54d3d4",
      "ddd36b19323e4db2ae4f725215a93785"
     ]
    },
    "id": "RLoY9FdNkShI",
    "outputId": "b4ce522e-11ac-4b82-f872-4268fb6baeac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b206eeab8ad04f6d9d95cb44d0491622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e28c83b49e34b91a75a65f5c5e41d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e449ed4ff2d41c7bf8f9a44748c8b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/validation-00000-of-00001.par(…):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6d687a0ce143c98f2d1585e125035e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d325f23f1dee4b238626402c68c470f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHeam73wkTzH"
   },
   "source": [
    "**Preview one sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGy3QcQykWnx",
    "outputId": "ed40353e-b50d-422f-d001-d539288e5bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "{k: sample[k] for k in [\"context\", \"question\", \"answers\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl7i22w8kZGP"
   },
   "source": [
    "**Check average context and answer lengths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KPxVoKxkaeN",
    "outputId": "aa2263a2-2a49-46a7-823d-d6c85b284a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(119.8), np.float64(3.16), np.float64(124.0), np.float64(3.02))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_len(split):\n",
    "    ctx = np.mean([len(x[\"context\"].split()) for x in split])\n",
    "    ans = np.mean([len(x[\"answers\"][\"text\"][0].split()) for x in split])\n",
    "    return round(ctx, 1), round(ans, 2)\n",
    "\n",
    "avg_ctx_train, avg_ans_train = avg_len(dataset[\"train\"])\n",
    "avg_ctx_val,   avg_ans_val   = avg_len(dataset[\"validation\"])\n",
    "(avg_ctx_train, avg_ans_train, avg_ctx_val, avg_ans_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHrVZouYkgCE"
   },
   "source": [
    "**Save smaller subsets for quick tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWKohU-Nki5T",
    "outputId": "501a0b9b-baca-4929-92e0-bedc380178d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train = dataset[\"train\"].select(range(3000))\n",
    "small_val   = dataset[\"validation\"].select(range(500))\n",
    "len(small_train), len(small_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QV8ZRq2wkrJW"
   },
   "source": [
    "# **2. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAEZhIhYksmT"
   },
   "source": [
    "**Import tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xWrcSXXxkubp"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUiFUfKvkwtk"
   },
   "source": [
    "**Choose all model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196,
     "referenced_widgets": [
      "acbd8c6337c9423e9138b59e619fcde4",
      "f8f89cc7a24a41c6af3a1276d403861f",
      "109f8548d92f402db3fd642a75dfa1ef",
      "5b600999cb17486b94f68e0daaba5be2",
      "baf20158976e4ca78255c7dc864528e5",
      "8b5225d571f54e43a0c751cb3b0abc6e",
      "c2c631ce16a64da68959cdb34a36befe",
      "fdbbca1af1bf488ea132fae3a7cf2c87",
      "23f9b50730c649b9a736e7734def67e7",
      "e8df373b83f446468d35789937d193fc",
      "da336a40a49c4e538c3c199de89423a8",
      "b68a45bd0fad48bc93aaac3db3702d47",
      "88086ff2f79f43bb8cb7397041eee9b6",
      "c8307fc586844c2787b38214befa6a38",
      "2e663923394a4d0e973e1e62d668c25d",
      "63b670483aa04ab4871643f2372b506a",
      "b38f5bcfea494706994dfe416bef0a8d",
      "f63bd2d49275489988ea55f443bf582e",
      "e55ed2dd52aa47f08603c40ab710323d",
      "87d9b15a9d4b4288a8e6f524df3905bd",
      "9cc8393643f748128e2fcfb335b19442",
      "6250eb6319604a57b69aca58fac6eeb3",
      "d289869be8e8480c8cfe806869d5b093",
      "94e1bc253ee84b1baa4dec4b7b35dcfb",
      "1cc4551b6b5a43f4808a06e340ab6eb9",
      "c86dbf20495748ebabe90d8541527045",
      "d4b668df1b5943f9953b880fc580f171",
      "e23865b9e0784f189c7542acaf28eda9",
      "b28bff335c3942d3bc888152f6569e37",
      "adc7b47be255471eb76ae0e5fb1f865a",
      "0a275b2bfe974a6dbcceb01ebf46b654",
      "f706e8f071cb4430897eeb59180122c6",
      "9f73c1dfa03544968245b4aba5e9f293",
      "340de95d785c4ec4b6a7dbdaa7fd8d48",
      "c9a988fb54484605bf7cc6abf3ab0ce9",
      "8483b3125157478c9bc6a382c505fce7",
      "a7a6bc32612f4fb4836ef209d629272d",
      "af6919d5d71b478a8f268e35152c7cc0",
      "7e2d97fc666f4484b9cdda2e909da9d6",
      "15e6b7758ab04df190bced40fd952587",
      "f98392f2c93f41018f8b6b423baddeca",
      "d715544a5ceb4e128f23f00be9e89fbc",
      "de2246b10b0346a685aaddf53b412db3",
      "a0bda9e2ebbb4098b9adb93d499a0263",
      "38be122a83954256bbc277dfdfb3abc0",
      "32a7f98dca90475f87b6196853a7f5d0",
      "8ed1cc2f400049c1b6646c03887f6f99",
      "0512dc47e3764c3f9a2cf56131cbd734",
      "f14e6e46d7ef4dd98eb0f333f3d9267e",
      "716d816d3b5a4bfb914c8226dc8020c4",
      "9730645da4b444b3b11627be2cc5240f",
      "f47660866029483492fe6b450ad86a6b",
      "19d4c176a14d49dfb2337002c58f1224",
      "fb8689260c9044e0862b241cdffc2c83",
      "b5991afa9bc640879025c8d6bdb0dd91"
     ]
    },
    "id": "2nfQsR4_kyae",
    "outputId": "ecaf4ec8-41d4-41d8-a370-28e1e21c520e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbd8c6337c9423e9138b59e619fcde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68a45bd0fad48bc93aaac3db3702d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d289869be8e8480c8cfe806869d5b093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340de95d785c4ec4b6a7dbdaa7fd8d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38be122a83954256bbc277dfdfb3abc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'roberta-base'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "tokenizer.name_or_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JrQLxnek23L"
   },
   "source": [
    "**Tokenization setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_nx7vFfk6Py",
    "outputId": "8f5c1160-1760-42dc-fe88-a1dda2213443"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 128, True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_lengths(tok, desired_max=384, desired_stride=128):\n",
    "    m = tok.model_max_length if isinstance(tok.model_max_length, int) else 512\n",
    "    max_len = min(desired_max, m)\n",
    "    stride  = min(desired_stride, max_len - 32) if max_len > 32 else max(1, max_len // 4)\n",
    "    return max_len, stride\n",
    "\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "max_length, doc_stride = safe_lengths(tokenizer)\n",
    "max_length, doc_stride, pad_on_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiT6B4rDk8Iz"
   },
   "source": [
    "**training feature builder (per tokenizer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GPigSRoDoB0t"
   },
   "outputs": [],
   "source": [
    "def make_prepare_train_features(tok):\n",
    "    pad_on_right = tok.padding_side == \"right\"\n",
    "    max_length, doc_stride = safe_lengths(tok)\n",
    "\n",
    "    def _fn(examples):\n",
    "        tokenized = tok(\n",
    "            examples[\"question\" if pad_on_right else \"context\"],\n",
    "            examples[\"context\"  if pad_on_right else \"question\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "        sample_map     = tokenized.pop(\"overflow_to_sample_mapping\")\n",
    "        offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "        start_positions, end_positions = [], []\n",
    "\n",
    "        for i, offsets in enumerate(offset_mapping):\n",
    "            input_ids = tokenized[\"input_ids\"][i]\n",
    "            cls_index = input_ids.index(tok.cls_token_id) if tok.cls_token_id in input_ids else 0\n",
    "            sample_idx = sample_map[i]\n",
    "            answers = examples[\"answers\"][sample_idx]\n",
    "\n",
    "            if len(answers[\"answer_start\"]) == 0:\n",
    "                start_positions.append(cls_index)\n",
    "                end_positions.append(cls_index)\n",
    "                continue\n",
    "\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char   = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            sequence_ids = tokenized.sequence_ids(i)\n",
    "\n",
    "            idx = 0\n",
    "            ctx_id = 1 if pad_on_right else 0\n",
    "            while idx < len(sequence_ids) and sequence_ids[idx] != ctx_id:\n",
    "                idx += 1\n",
    "            context_start = idx\n",
    "            while idx < len(sequence_ids) and sequence_ids[idx] == ctx_id:\n",
    "                idx += 1\n",
    "            context_end = idx - 1\n",
    "\n",
    "            if context_start >= len(offsets) or context_end < 0:\n",
    "                start_positions.append(cls_index)\n",
    "                end_positions.append(cls_index)\n",
    "                continue\n",
    "\n",
    "            if not (offsets[context_start] and offsets[context_start][0] <= start_char and\n",
    "                    offsets[context_end]   and offsets[context_end][1]   >= end_char):\n",
    "                start_positions.append(cls_index)\n",
    "                end_positions.append(cls_index)\n",
    "            else:\n",
    "                while context_start < len(offsets):\n",
    "                    o = offsets[context_start]\n",
    "                    if o and o[0] <= start_char < o[1]:\n",
    "                        break\n",
    "                    context_start += 1\n",
    "\n",
    "                while context_end >= 0:\n",
    "                    o = offsets[context_end]\n",
    "                    if o and o[0] < end_char <= o[1]:\n",
    "                        break\n",
    "                    context_end -= 1\n",
    "\n",
    "                start_positions.append(context_start if context_start >= 0 else cls_index)\n",
    "                end_positions.append(context_end   if context_end   >= 0 else cls_index)\n",
    "\n",
    "        tokenized[\"start_positions\"] = start_positions\n",
    "        tokenized[\"end_positions\"]   = end_positions\n",
    "        return tokenized\n",
    "\n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FKAqFJkr4kh"
   },
   "source": [
    "**validation feature builder (per tokenizer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KXp2xoF5r67I"
   },
   "outputs": [],
   "source": [
    "def make_prepare_validation_features(tok):\n",
    "    pad_on_right = tok.padding_side == \"right\"\n",
    "    max_length, doc_stride = safe_lengths(tok)\n",
    "\n",
    "    def _fn(examples):\n",
    "        tokenized = tok(\n",
    "            examples[\"question\" if pad_on_right else \"context\"],\n",
    "            examples[\"context\"  if pad_on_right else \"question\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "        sample_map = tokenized.pop(\"overflow_to_sample_mapping\")\n",
    "        tokenized[\"example_id\"] = []\n",
    "\n",
    "        for i in range(len(tokenized[\"input_ids\"])):\n",
    "            sample_idx = sample_map[i]\n",
    "            tokenized[\"example_id\"].append(examples[\"id\"][sample_idx])\n",
    "\n",
    "            sequence_ids = tokenized.sequence_ids(i)\n",
    "            ctx_id = 1 if pad_on_right else 0\n",
    "            offsets = tokenized[\"offset_mapping\"][i]\n",
    "            tokenized[\"offset_mapping\"][i] = [\n",
    "                o if sequence_ids[k] == ctx_id else None\n",
    "                for k, o in enumerate(offsets)\n",
    "            ]\n",
    "\n",
    "        return tokenized\n",
    "\n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtrS6Trxr_Oc"
   },
   "source": [
    "**Map features for every model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "587fcb3212514d5b8e381de7e6b51773",
      "a4a571922d6342939c6bcdacef57e643",
      "6b84eb0a40c44939b8f1bdb4bc873b96",
      "0149476f095f4936b15b5df7b4d6a49b",
      "07c21a35661149a1900c0389947e5f5c",
      "00ccfba4a3c548b38b27ae4098f86298",
      "57f428e703ca4c61bcb9cc76c1e05c96",
      "37bd9d75debd43c795c60404d03fd0fe",
      "ac881f5e392d4ca1b18a257d59b6f6b9",
      "99fd390e486e47b49d5b533abbc3f490",
      "2d1a1e4135f14a09a26851440fd75d20",
      "81542c118cc04608a9e1e4488a59a4dd",
      "2fb8c349c64e4bc09dd569485c27d27a",
      "e21705f351f94ef1b5b381f958c486b2",
      "151226633694489abf33b592e9edb334",
      "b51879a045074ab5a92f4bf3ea2d6836",
      "506dac58bfa642e0a759cb6e3f52ee9d",
      "0a7a5969fc014dbf93b792b33348fed3",
      "0e82b72f2ec944ed8265f6d6882b7f05",
      "b51a532f72c0493196e34cd11c077397",
      "b9dc44b067954b919c2611664177cffb",
      "63bcaa52d1144f9c9d952d885be46de3"
     ]
    },
    "id": "zTGtm9nur_-g",
    "outputId": "e0e206ff-d71e-423b-da53-ad93fc86e919"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587fcb3212514d5b8e381de7e6b51773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81542c118cc04608a9e1e4488a59a4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(88756, 10790)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = dataset[\"train\"].map(\n",
    "    make_prepare_train_features(tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "validation_features = dataset[\"validation\"].map(\n",
    "    make_prepare_validation_features(tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names\n",
    ")\n",
    "\n",
    "len(train_features), len(validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA96D3xFvqoH"
   },
   "source": [
    "**Quick sanity check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzeUX2aIvouU",
    "outputId": "b8f92085-6ddd-4b3c-c4b3-798d5b83d0ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       " ['input_ids', 'attention_mask', 'offset_mapping', 'example_id'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train = train_features[0]\n",
    "example_val   = validation_features[0]\n",
    "list(example_train.keys()), list(example_val.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epLBWjaKoDRn"
   },
   "source": [
    "# **3. Model & Training — roberta**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9XzVKosoFG2"
   },
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9MhJrc07oJ2A"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBNucjY9oK_T"
   },
   "source": [
    "**SQuAD metric and small constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "61a0ff4a833c484f9d2a8b765150688c",
      "30d4487b3f1e49a78cebfe412adebb0c",
      "8250d10c320b4530b963b05dbb35e812",
      "8e20a400d0854b6783e72cfb1f78f096",
      "2d6aa464b8af402587571a87e5797c82",
      "00fccb1fcef8422fa9c314a6e51f449a",
      "5953f5b0ebd0426587a98283f36a93a0",
      "ee07bcebbcc047749ebcc4d0a61dad21",
      "4d362e880ec543308e11c6db71e3241b",
      "48cb1c7549444d0c8b1edb2714b3262a",
      "6ea75bdb4ed247509625ec265adf42f7",
      "ab7a8fa531dd40bdb15601cf18a437b8",
      "3812364c8cdd46148b465842b67744e0",
      "414c6a8d578042dfbb3db62f1eaec00c",
      "3e76aa53d9f24aebad48cf35fe1e75cf",
      "8cfd9760bc0d4127af34e13c1fa683c7",
      "8d42491ce3e54589af49d84b951ef57e",
      "3e3a6ccc7ad14256a1f444af8ccdf7ea",
      "9c936982ef074a5da4c553fb702b7eaa",
      "f3b6d9fcde15405d8ba3b915aff12cc7",
      "3419565c962a4f729b42774352afed3b",
      "fddbe9e328014ef59c992a079448783e"
     ]
    },
    "id": "fCjkTYf9oNGX",
    "outputId": "85dbe9e3-b894-49c9-e4fd-e0fccd310084"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a0ff4a833c484f9d2a8b765150688c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7a8fa531dd40bdb15601cf18a437b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"squad\")\n",
    "n_best = 20\n",
    "max_answer_len = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhKzzQD1oOW3"
   },
   "source": [
    "**Post‑processing to convert logits → text spans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XldGeXkkoQWJ"
   },
   "outputs": [],
   "source": [
    "def postprocess_qa_predictions(examples, features, raw_predictions):\n",
    "    start_logits, end_logits = raw_predictions\n",
    "    id2idx = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    feats_per_ex = {}\n",
    "    for i, f in enumerate(features):\n",
    "        ex_idx = id2idx[f[\"example_id\"]]\n",
    "        feats_per_ex.setdefault(ex_idx, []).append(i)\n",
    "\n",
    "    preds = []\n",
    "    for ex_idx, ex in enumerate(examples):\n",
    "        ctx = ex[\"context\"]\n",
    "        f_idxs = feats_per_ex.get(ex_idx, [])\n",
    "        cand = []\n",
    "        for fi in f_idxs:\n",
    "            s_log = start_logits[fi]\n",
    "            e_log = end_logits[fi]\n",
    "            offsets = features[fi][\"offset_mapping\"]\n",
    "            s_idx = np.argsort(s_log)[-n_best:]\n",
    "            e_idx = np.argsort(e_log)[-n_best:]\n",
    "            for s in s_idx:\n",
    "                for e in e_idx:\n",
    "                    if s >= len(offsets) or e >= len(offsets):\n",
    "                        continue\n",
    "                    if offsets[s] is None or offsets[e] is None:\n",
    "                        continue\n",
    "                    if e < s or (e - s + 1) > max_answer_len:\n",
    "                        continue\n",
    "                    score = float(s_log[s] + e_log[e])\n",
    "                    cand.append((score, offsets[s][0], offsets[e][1]))\n",
    "        if not cand:\n",
    "            preds.append({\"id\": ex[\"id\"], \"prediction_text\": \"\"})\n",
    "        else:\n",
    "            best = max(cand, key=lambda x: x[0])\n",
    "            preds.append({\"id\": ex[\"id\"], \"prediction_text\": ctx[best[1]:best[2]]})\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pmdCd-32SgE"
   },
   "source": [
    "**Metric callback factory per model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qvkN0goE2Vy1"
   },
   "outputs": [],
   "source": [
    "def make_compute_metrics(model_name):\n",
    "    val_feats = validation_features\n",
    "    val_examples = dataset[\"validation\"]\n",
    "    def _fn(eval_pred):\n",
    "        raw = eval_pred.predictions if hasattr(eval_pred, \"predictions\") else eval_pred\n",
    "        preds = postprocess_qa_predictions(val_examples, val_feats, raw)\n",
    "        refs = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in val_examples]\n",
    "        return metric.compute(predictions=preds, references=refs)\n",
    "    return _fn\n",
    "\n",
    "compute_metrics_single = make_compute_metrics(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVosgCqF2Sjj"
   },
   "source": [
    "**TrainingArguments helper that works on old and new transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vjQVzKSPz-dA"
   },
   "outputs": [],
   "source": [
    "def make_args(output_stem, lr=3e-5, bs=16, epochs=2, fp16=torch.cuda.is_available()):\n",
    "    out = f\"./qa_runs_{output_stem.replace('/', '_')}\"\n",
    "    try:\n",
    "        return TrainingArguments(\n",
    "            output_dir=out,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=bs,\n",
    "            per_device_eval_batch_size=bs,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=0.01,\n",
    "            fp16=fp16,\n",
    "            logging_steps=100,\n",
    "            report_to=\"none\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            greater_is_better=True\n",
    "        )\n",
    "    except TypeError:\n",
    "        return TrainingArguments(\n",
    "            output_dir=out,\n",
    "            do_train=True,\n",
    "            do_eval=True,\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=bs,\n",
    "            per_device_eval_batch_size=bs,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=0.01,\n",
    "            fp16=fp16,\n",
    "            logging_steps=100,\n",
    "            report_to=\"none\",\n",
    "            save_total_limit=2,\n",
    "            save_steps=1000,\n",
    "            eval_steps=1000\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyLNLhRz0CDO"
   },
   "source": [
    "**Build trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "id": "VwX1peFl0AV7"
   },
   "outputs": [],
   "source": [
    "def build_trainer_single(model, args):\n",
    "    try:\n",
    "      return Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=train_features,\n",
    "            eval_dataset=validation_features,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=default_data_collator,\n",
    "            compute_metrics=compute_metrics_single\n",
    "        )\n",
    "\n",
    "    except TypeError:\n",
    "        return Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=train_features,\n",
    "            eval_dataset=validation_features,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=default_data_collator,\n",
    "            compute_metrics=compute_metrics_single\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d6ffea3bebfe4f3b8c2670399ca7c7a2",
      "2906e69b0d15416ebc9c287c9e3d1cc3",
      "acf70a1ffe564ea5a1ad1ab39128ee19",
      "0cb4fa7970a04ccba31e4c844a81eefa",
      "182873b8a27f47e5ba3042da26903787",
      "aa2950e416224b08b68cf4c4f43f1f61",
      "59983114a02c4bae9855acf6f7d44c4d",
      "2b7df4b6c9a74f739fd44bde5e410487",
      "00ad95089a544df9b16be40c6eb12eea",
      "a08e27d907f047579ec3f1920081d4a2",
      "ac18c70f82b4442e85d19a036dbaef8c"
     ]
    },
    "collapsed": true,
    "id": "ya4aQSYzPKtz",
    "outputId": "ba61549c-bcd6-4b7d-ddf0-2731a4b63d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training roberta-base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ffea3bebfe4f3b8c2670399ca7c7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11096' max='11096' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11096/11096 57:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.357400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.199400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.977600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.983300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.956400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.997800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.903300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.887900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.953700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.894700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.888800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.922400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.860500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.878300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.871200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.800300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.687900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.698700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.698300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.703500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.690800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.636100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.652800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.661300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.651600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.625900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.616800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.640100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.637400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.574200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.656700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"roberta-base\"\n",
    "print(f\"=== Training {name} ===\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(name)\n",
    "args  = make_args(name)\n",
    "trainer = build_trainer_single(model, args)\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMXKQXL4PNu3",
    "outputId": "3c026853-f084-4f4c-c5ae-9bfcf535ead6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qa_model_roberta-base/tokenizer_config.json',\n",
       " './qa_model_roberta-base/special_tokens_map.json',\n",
       " './qa_model_roberta-base/vocab.json',\n",
       " './qa_model_roberta-base/merges.txt',\n",
       " './qa_model_roberta-base/added_tokens.json',\n",
       " './qa_model_roberta-base/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = f\"./qa_model_{name.replace('/', '_')}\"\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "C_Qwty7_PPjJ",
    "outputId": "1e56cadd-af8f-4538-d896-bbed2c86e67e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 55.6076,\n        \"max\": 55.6076,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          55.6076\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 194.038,\n        \"max\": 194.038,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          194.038\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 12.139,\n        \"max\": 12.139,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12.139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_results"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-382be5b5-3863-4948-8572-3a03cd71ec13\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>55.6076</td>\n",
       "      <td>194.038</td>\n",
       "      <td>12.139</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-382be5b5-3863-4948-8572-3a03cd71ec13')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-382be5b5-3863-4948-8572-3a03cd71ec13 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-382be5b5-3863-4948-8572-3a03cd71ec13');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_5ee12c0a-5871-4eee-b326-434404a89409\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_5ee12c0a-5871-4eee-b326-434404a89409 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_results');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          model  eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "0  roberta-base       55.6076                  194.038                 12.139   \n",
       "\n",
       "   epoch  \n",
       "0    2.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame([{\"model\": name, **{k: float(v) for k, v in metrics.items()}}])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T47hPr4hoX-n"
   },
   "source": [
    "# **4. Inference & Quick Sanity Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ROOEauEoZc5"
   },
   "source": [
    "**Load the fine‑tuned checkpoint for this model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YIuOZE8docM2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "CKPT_DIR   = f\"./qa_model_{MODEL_NAME.replace('/', '_')}\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(CKPT_DIR, use_fast=True)\n",
    "model      = AutoModelForQuestionAnswering.from_pretrained(CKPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RV_k_rNodZH"
   },
   "source": [
    "**Build the QA pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJiX2ZFIoe8x",
    "outputId": "efb5f066-91fd-4a67-f9ed-35a8f16c3c0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrZTOcsIogS4"
   },
   "source": [
    "**Example context and question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzixtPfsohqF",
    "outputId": "5cc47505-dfcc-44af-896a-045e19e0b7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which river is the longest in the world?\n",
      "Answer: The Nile River\n",
      "Score: 0.5751\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "The Nile River is the longest river in the world, flowing northward through\n",
    "eastern Africa into the Mediterranean Sea. It has historically been of great\n",
    "importance to Egyptian civilization.\n",
    "\"\"\"\n",
    "question = \"Which river is the longest in the world?\"\n",
    "\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "print(\"Score:\", round(result[\"score\"], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZx-IO8dor7I"
   },
   "source": [
    "# **5. Export (checkpoint)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2fgUiN9os3i"
   },
   "source": [
    "**Set paths for this model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "yKYJeWZDot_t",
    "outputId": "01046d36-cd72-464a-bcf1-a5c41406bd7b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./qa_model_roberta-base'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, pathlib\n",
    "\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "CKPT_DIR   = f\"./qa_model_{MODEL_NAME.replace('/', '_')}\"\n",
    "pathlib.Path(CKPT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCiBbzvZovVr"
   },
   "source": [
    "**Save final checkpoint (model + tokenizer + a mini card)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5N_NRccoxuX",
    "outputId": "9e839c45-d014-489d-b492-fd6372dc1733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to: ./qa_model_roberta-base\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "_ = AutoModelForQuestionAnswering.from_pretrained(CKPT_DIR).save_pretrained(CKPT_DIR)\n",
    "_ = AutoTokenizer.from_pretrained(CKPT_DIR).save_pretrained(CKPT_DIR)\n",
    "\n",
    "with open(os.path.join(CKPT_DIR, \"model_card.txt\"), \"w\") as f:\n",
    "    f.write(f\"Model: {MODEL_NAME}\\n\")\n",
    "    f.write(\"Notes: Fine-tuned on SQuAD v1.1 for extractive QA\\n\")\n",
    "\n",
    "print(\"Saved checkpoint to:\", CKPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rJS_SqlffFH"
   },
   "source": [
    "**Write metrics JSON (EM/F1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "YjEQjEonfg53",
    "outputId": "f8f08e81-b32a-4410-f9ef-55626e95bb97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'roberta-base',\n",
       " 'metrics': {'eval_runtime': 57.6057,\n",
       "  'eval_samples_per_second': 187.308,\n",
       "  'eval_steps_per_second': 11.718,\n",
       "  'epoch': 2.0,\n",
       "  'exact_match': 85.96972563859981,\n",
       "  'f1': 92.08548815741908}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Evaluate runtime metrics (loss, eval_runtime, etc.)\n",
    "runtime_metrics = trainer.evaluate()\n",
    "\n",
    "# Step 2: Evaluate EM and F1 using predictions\n",
    "raw_predictions = trainer.predict(validation_features)\n",
    "qa_metrics = compute_metrics_single(raw_predictions)\n",
    "\n",
    "# Step 3: Merge both\n",
    "all_metrics = {**runtime_metrics, **qa_metrics}\n",
    "\n",
    "# Step 4: Save to JSON\n",
    "metrics_out = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"metrics\": {k: float(v) for k, v in all_metrics.items()}\n",
    "}\n",
    "with open(f\"./metrics_{MODEL_NAME.replace('/', '_')}.json\", \"w\") as f:\n",
    "    json.dump(metrics_out, f, indent=2)\n",
    "\n",
    "metrics_out"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
